# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "e5c91cba-9256-479f-b70e-d62371bf8d1b",
# META       "default_lakehouse_name": "LH_happy_booking",
# META       "default_lakehouse_workspace_id": "271e3823-9a84-4561-bfe9-0be145a4a022",
# META       "known_lakehouses": [
# META         {
# META           "id": "e5c91cba-9256-479f-b70e-d62371bf8d1b"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

from pyspark.sql import functions as F
from pyspark.sql.window import Window
from pyspark.sql.functions import create_map, lit, col

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 1. BRONZE VERÄ°SÄ°NÄ° OKU


# CELL ********************

batch_df = spark.read.table("hotel_raw_batch")
initial_count = batch_df.count()

print(f"ğŸ“¦ Bronze katmanÄ±ndan {initial_count} adet ham kayÄ±t baÅŸarÄ±yla yÃ¼klendi.")
print("ğŸ“‹ Ä°lk 5 satÄ±r Ã¶rneÄŸi:")
display(batch_df.limit(15))

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 2. TEKÄ°LLEÅTÄ°RME (Deduplication)

# CELL ********************

cleaned_df = batch_df.dropDuplicates(["booking_id"])
after_dedup_count = cleaned_df.count()
dup_removed = initial_count - after_dedup_count

print("="*40)
print("ğŸ“Š DEDUPLICATION REPORT")
print("="*40)
print(f"ğŸ“¥ BaÅŸlangÄ±Ã§ SatÄ±r SayÄ±sÄ±:   {initial_count}")
print(f"ğŸ§¹ Silinen Tekrar KayÄ±t:    {dup_removed}")
print(f"âœ… Kalan Tekil KayÄ±t:       {after_dedup_count}")
print(f"ğŸ“ˆ Veri Temizlik OranÄ±:    %{round((dup_removed/initial_count)*100, 2)}")
print("="*40)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 3. KARAKTER TEMÄ°ZLÄ°ÄÄ° ([!@#$%^&*().,])

# CELL ********************

# Ãœnlem (!!) ve diÄŸer Ã¶zel karakterleri tÃ¼m kritik kolonlardan temizliyoruz
text_cols = ["hotel_id", "country_customer", "country", "city", "full_name", "hotel_name", "city_customer", "address", "room_type"]

for col_name in text_cols:
    if col_name in cleaned_df.columns:
        cleaned_df = cleaned_df.withColumn(
            col_name, 
            F.trim(F.regexp_replace(F.col(col_name), r"[!@#$%^&*().,]", ""))
        )

print("ğŸ§¹ 1. KARAKTER TEMÄ°ZLÄ°ÄÄ°: 'hotel_id' ve 'country_customer' sÃ¼tunlarÄ± temizlendi.")
print("ğŸ“‹ Ä°lk 5 satÄ±r Ã¶rneÄŸi:")
display(batch_df.limit(5))

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 4. TEMÄ°ZLÄ°K & STANDARTLAÅTIRMA (Regex, Phone, Coords)

# CELL ********************

# Telefon StandartlaÅŸtÄ±rma
if "phone" in cleaned_df.columns:
    cleaned_df = cleaned_df.withColumn("phone", F.regexp_replace(F.col("phone"), r"[^0-9]", ""))

if "phone" in cleaned_df.columns:
    print(f"ğŸ“ Telefon: Ã–zel karakterler temizlendi, sadece rakamlar tutuldu.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

#Koordinat StandartlaÅŸtÄ±rma

for coord in ["latitude", "longitude"]:
    if coord in cleaned_df.columns:
        cleaned_df = cleaned_df.withColumn(coord, F.col(coord).cast("double"))

cleaned_df = cleaned_df.withColumn(
    "latitude", 
    F.when(F.col("latitude").between(-90, 90) & (F.col("latitude") != 0), F.round(F.col("latitude"), 6))
).withColumn(
    "longitude", 
    F.when(F.col("longitude").between(-180, 180) & (F.col("longitude") != 0), F.round(F.col("longitude"), 6))
)

print(f"ğŸ“ Koordinatlar: Double tipine Ã§evrildi ve 6 haneye yuvarlandÄ±.")
print(f"   - Latitude aralÄ±ÄŸÄ± : [-90, 90]")
print(f"   - Longitude aralÄ±ÄŸÄ±: [-180, 180]")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Formatlama Ä°ÅŸlemleri
cleaned_df = cleaned_df.withColumn("country", F.upper(F.col("country"))) \
                       .withColumn("country_customer", F.upper(F.col("country_customer"))) \
                       .withColumn("hotel_id", F.upper(F.col("hotel_id"))) \
                       .withColumn("full_name", F.initcap(F.col("full_name"))) \
                       .withColumn("hotel_name", F.initcap(F.col("hotel_name"))) \
                       .withColumn("city", F.initcap(F.col("city"))) \
                       .withColumn("city_customer", F.initcap(F.col("city_customer"))) \
                       .withColumn("email", F.lower(F.trim(F.col("email")))) \
                       .withColumn("room_type", F.upper(F.trim(F.col("room_type")))) \
                       .withColumn("trip_type", F.initcap(F.trim(F.col("trip_type"))))


print("ğŸ”  GeniÅŸletilmiÅŸ Metin Formatlama TamamlandÄ±:")
print("   - Ãœlkeler ve Hotel ID -> BÃœYÃœK HARF (StandartlaÅŸtÄ±rma)")
print("   - Ä°simler, Åehirler ve Seyahat Tipi -> BaÅŸ Harf BÃ¼yÃ¼k (GÃ¶rsel DÃ¼zen)")
print("   - Oda Tipleri -> BÃœYÃœK HARF (EÅŸleÅŸme KolaylÄ±ÄŸÄ±)")
print("   - Email -> kÃ¼Ã§Ã¼k harf & boÅŸluksuz (Veri BÃ¼tÃ¼nlÃ¼ÄŸÃ¼)")

print("\nğŸ“‹ FormatlanmÄ±ÅŸ Veriden Ã–rnek (Ä°lk 5 SatÄ±r):")

display(cleaned_df.select("hotel_id", "full_name", "country_customer", "room_type", "email").limit(5))

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 5. GLOBAL LANGUAGE PREFERENCE MAPPING

# CELL ********************

# 1. BaÅŸlangÄ±Ã§ Durumu (Kolon henÃ¼z yok, dolayÄ±sÄ±yla tÃ¼m satÄ±rlar 'boÅŸ' kabul edilir)
total_count = cleaned_df.count()
print(f"ğŸ” Ä°ÅŸlem Ã–ncesi: 'language_preference' kolonu henÃ¼z yok (Potansiyel: {total_count} boÅŸ kayÄ±t)")

# 2. SÃ¶zlÃ¼ÄŸÃ¼ HazÄ±rla ve Uygula
language_map = {
    "TURKEY": "Turkish", "TUR": "Turkish", "GERMANY": "German", "DEU": "German",
    "FRANCE": "French", "FRA": "French", "SPAIN": "Spanish", "ESP": "Spanish",
    "ITALY": "Italian", "ITA": "Italian", "UNITED KINGDOM": "English", "GBR": "English",
    "PORTUGAL": "Portuguese", "PRT": "Portuguese", "RUSSIA": "Russian", "RUS": "Russian",
    "NETHERLANDS": "Dutch", "NLD": "Dutch", "POLAND": "Polish", "POL": "Polish",
    "USA": "English", "UNITED STATES": "English", "BRAZIL": "Portuguese", "BRA": "Portuguese",
    "ARGENTINA": "Spanish", "ARG": "Spanish", "MEXICO": "Spanish", "MEX": "Spanish",
    "CHINA": "Chinese", "CHN": "Chinese", "JAPAN": "Japanese", "JPN": "Japanese",
    "AUSTRALIA": "English", "AUS": "English", "INDIA": "Hindi/English", "IND": "Hindi/English",
    "SOUTH AFRICA": "English/Afrikaans", "NEW ZEALAND": "English", "VIETNAM": "Vietnamese",
    "NORWAY": "Norwegian", "PHILIPPINES": "Filipino/English", "MEXICO": "Spanish",
    "CZECH REPUBLIC": "Czech", "NIGERIA": "English", "CROATIA": "Croatian",
    "SOUTH KOREA": "Korean", "CANADA": "English/French", "SWEDEN": "Swedish",
    "MALAYSIA": "Malay", "SLOVAKIA": "Slovak", "COLOMBIA": "Spanish",
    "FINLAND": "Finnish", "UNITED ARAB EMIRATES": "Arabic", "MOROCCO": "Arabic/Berber",
    "SINGAPORE": "English/Mandarin", "ROMANIA": "Romanian", "THAILAND": "Thai",
    "SAUDI ARABIA": "Arabic", "AUSTRIA": "German", "ISRAEL": "Hebrew",
    "NETHERLANDS": "Dutch", "ARGENTINA": "Spanish", "CHILE": "Spanish",
    "BELGIUM": "Dutch/French", "SWITZERLAND": "German/French/Italian", "BULGARIA": "Bulgarian",
    "SERBIA": "Serbian", "HUNGARY": "Hungarian", "PERU": "Spanish", "GREECE": "Greek",
    "KENYA": "Swahili/English", "POLAND": "Polish", "DENMARK": "Danish",
    "IRELAND": "English/Irish", "EGYPT": "Arabic", "INDONESIA": "Indonesian"
}

lang_expr = create_map([lit(x) for x in sum(language_map.items(), ())])
cleaned_df = cleaned_df.withColumn("language_preference", lang_expr[F.col("country_customer")])

# 3. Ä°ÅŸlem SonrasÄ± Durumu
filled_count = cleaned_df.filter(F.col("language_preference").isNotNull()).count()
still_null_count = total_count - filled_count

success_rate = round((filled_count / total_count) * 100, 2)
missing_rate = round((still_null_count / total_count) * 100, 2)

print("-" * 50)
print(f"âœ… Ä°ÅŸlem TamamlandÄ±!")
print(f"ğŸ“ Toplam {total_count} kayÄ±ttan {filled_count} tanesi dil bilgisiyle dolduruldu.")
print(f"ğŸ“Š BaÅŸarÄ± OranÄ±: %{success_rate}")
print(f"âš ï¸  {still_null_count} kayÄ±t (%{missing_rate}) sÃ¶zlÃ¼kte bulunamadÄ±ÄŸÄ± iÃ§in boÅŸ kaldÄ±.")
print("-" * 50)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 6. DÄ°ÄER TARÄ°HLER VE FÄ°LTRELEME

# CELL ********************

date_columns = ["booking_date", "birth_date", "stay_date"]
for col in date_columns:
    if col in cleaned_df.columns:
        cleaned_df = cleaned_df.withColumn(col, F.to_date(F.col(col)))

pre_filter_count = cleaned_df.count()
null_ids_count = cleaned_df.filter(F.col("hotel_id").isNull() | F.col("booking_id").isNull()).count()

cleaned_df = cleaned_df.na.drop(subset=["hotel_id", "booking_id"])
cleaned_df = cleaned_df.filter(
    (F.col("total_price") > 0) & (F.col("adults") > 0) & 
    (F.col("star_rating").between(1, 5)) & (F.col("nights") > 0)
)

final_count = cleaned_df.count()
logical_filter_removed = pre_filter_count - final_count

print("="*50)
print("ğŸ›¡ï¸ DATA QUALITY & LOGICAL FILTERING REPORT")
print("="*50)

print(f"ğŸ“¥ Filtreleme Ã–ncesi Toplam KayÄ±t: {pre_filter_count}")
print(f"âŒ Kritik ID'si (Hotel/Booking) Eksik: {null_ids_count}")
print(f"ğŸ§¹ MantÄ±ksal Hatalar Nedeniyle Silinen: {logical_filter_removed - null_ids_count}")
print(f"--------------------------------------------------")
print(f"âœ… Filtreleme SonrasÄ± Temiz KayÄ±t   : {final_count}")
print(f"ğŸ“‰ Veri KaybÄ± OranÄ±                 : %{round(((pre_filter_count - final_count) / pre_filter_count) * 100, 2)}")
print("="*50)

# Ã–rnek bir veri kontrolÃ¼
if final_count > 0:
    print("ğŸ“‹ TemizlenmiÅŸ Veriden Ã–rnek (Ä°lk 3 SatÄ±r):")
    display(cleaned_df.select("hotel_id", "total_price", "adults", "nights").limit(3))

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 7. ENRICHMENT & API JOIN

# CELL ********************

try:
    # Euro kurunu Ã§ekiyoruz (EÄŸer raw_currency_api tablonuzda eur_rate varsa)
    eur_rate = spark.read.table("raw_currency_api").select("eur_rate").collect()[0][0]
    weather_temp = spark.read.table("raw_weather_api").select("temperature").collect()[0][0]

except:
    # EÄŸer API tablosu yoksa varsayÄ±lan Euro kurunu (Ã–rn: 1.08) ve sÄ±caklÄ±ÄŸÄ± atar
    eur_rate, weather_temp = 1.08, 20.0

# silver_final oluÅŸtururken total_price_eur kullanÄ±yoruz
silver_final = cleaned_df \
    .withColumn("total_price_eur", F.round(F.col("total_price") * eur_rate, 2)) \
    .withColumn("ingested_temp", F.lit(weather_temp)) \
    .withColumn("silver_processed_at", F.current_timestamp())

# --- ENRICHMENT SUMMARY ---
print("=" * 60)
print("ğŸ’¶ EXTERNAL DATA ENRICHMENT (EURO BASED)")
print("=" * 60)

status = "âœ… API'den GÃ¼ncel Euro Kuru AlÄ±ndÄ±" if eur_rate != 1.08 else "âš ï¸ API BaÅŸarÄ±sÄ±z (VarsayÄ±lan Euro Kuru KullanÄ±ldÄ±)"
print(f"ğŸ“¡ Durum: {status}")
print(f"ğŸ’¶ Uygulanan EUR Kuru: {eur_rate}")
print(f"ğŸŒ¡ï¸  Eklenen Hava Durumu: {weather_temp} Â°C")
print("-" * 60)

# Ã–rnek hesaplama saÄŸlamasÄ±
print("ğŸ§ Finansal DÃ¶nÃ¼ÅŸÃ¼m KontrolÃ¼ (â‚¬):")
display(silver_final.select("total_price", "total_price_eur").limit(3))

print("=" * 60)
print("ğŸš€ Silver KatmanÄ± Euro BazÄ±nda MÃ¼hÃ¼rlendi.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # ---------------------------------------------------------
# # 8. YAZMA

# CELL ********************

# Tabloyu tamamen sÄ±fÄ±rlayÄ±p en gÃ¼ncel haliyle yazÄ±yoruz
spark.sql("DROP TABLE IF EXISTS silver_hotel_bookings")

silver_final.write.format("delta") \
    .mode("overwrite") \
    .option("overwriteSchema", "true") \
    .saveAsTable("silver_hotel_bookings")

display(silver_final.limit(20))

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
